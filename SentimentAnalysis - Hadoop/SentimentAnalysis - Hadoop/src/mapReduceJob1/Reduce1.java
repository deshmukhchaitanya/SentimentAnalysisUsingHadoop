package mapReduceJob1;
import java.io.IOException;
import java.util.Iterator;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceBase;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reducer;
import org.apache.hadoop.mapred.Reporter;

/**
 * Reduce job1 for cleaning tweeter data by finding related tweets.
 * Input: Input data file generated by Map1 job.
 * Output: Tweet data file containing the user input query.
*/

public class Reduce1 extends MapReduceBase implements Reducer<Text, Text, Text, Text> {
	
	public static String userToken;
	
	public void configure(JobConf job) {
		userToken = job.get("userToken1");
	}
	
	public void reduce(Text key, Iterator<Text> values, OutputCollector<Text, Text> output, Reporter reporter) throws IOException {
		userToken = userToken.toLowerCase();
		String tweetData = new String();
		while (values.hasNext()) {
			tweetData = values.next().toString().toLowerCase();
			if( tweetData.matches("(?s).*\\b" + userToken + ".*")) {
				output.collect(key, new Text(tweetData)); 
			}
		}
	}
}